{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io\n",
    "import math\n",
    "import geneNewData\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def main():\n",
    "    myID='1391' #change to last 4 digit of your studentID\n",
    "    geneNewData.geneData(myID)\n",
    "    Numpyfile0 = scipy.io.loadmat('digit0_stu_train'+myID+'.mat')\n",
    "    Numpyfile1 = scipy.io.loadmat('digit1_stu_train'+myID+'.mat')\n",
    "    Numpyfile2 = scipy.io.loadmat('digit0_testset'+'.mat')\n",
    "    Numpyfile3 = scipy.io.loadmat('digit1_testset'+'.mat')\n",
    "    train0 = Numpyfile0.get('target_img')\n",
    "    train1 = Numpyfile1.get('target_img')\n",
    "    test0 = Numpyfile2.get('target_img')\n",
    "    test1 = Numpyfile3.get('target_img')\n",
    "    #print([len(train0),len(train1),len(test0),len(test1)])\n",
    "    #print('Your trainset and testset are generated successfully!')\n",
    "    prior_prob = 0.5\n",
    "\n",
    "    # extract the two features (mean and standard deviation) of each 28x28 image in the training sets\n",
    "    mean0, sd0 = extract_features(train0)\n",
    "    train0_2d = np.column_stack((mean0, sd0))\n",
    "    mean1, sd1 = extract_features(train1)\n",
    "    train1_2d = np.column_stack((mean1, sd1))   \n",
    "\n",
    "    # extract the two features (mean and standard deviation) of each 28x28 image in the testing sets\n",
    "    test_mean0, test_sd0 = extract_features(test0)\n",
    "    test0_2d = np.column_stack((test_mean0, test_sd0))\n",
    "    test_mean1, test_sd1 = extract_features(test1)\n",
    "    test1_2d = np.column_stack((test_mean1, test_sd1))\n",
    "\n",
    "    # calculate the parameters for the PDF of each class\n",
    "    mean_feature1_0, var_feature1_0 = calculate_parameters(mean0)\n",
    "    mean_feature2_0, var_feature2_0 = calculate_parameters(sd0)\n",
    "    mean_feature1_1, var_feature1_1 = calculate_parameters(mean1)\n",
    "    mean_feature2_1, var_feature2_1 = calculate_parameters(sd1)\n",
    "    \n",
    "    # P(x|y=0) = P(feature1 of x|y=0) * P(feature2 of x | y=0)  where x is a sample image from test0 \n",
    "    likelihood_0_testset0 = calculate_pdf(test_mean0, mean_feature1_0, var_feature1_0) * calculate_pdf(test_sd0, mean_feature2_0, var_feature2_0)\n",
    "    \n",
    "    # P(x|y=1) = P(feature1 of x|y=0) * P(feature2 of x | y=0)  where x is a sample image from test0\n",
    "    likelihood_1_testset0 = calculate_pdf(test_mean0, mean_feature1_1, var_feature1_1) * calculate_pdf(test_sd0, mean_feature2_1, var_feature2_1)\n",
    "    \n",
    "    # make a prediction whether a value in test0 belongs to class 0 or 1 by returning the the greater likelihood\n",
    "    #prediction_testset0 = (likelihood_0_testset0 > likelihood_1_testset0).astype(int)\n",
    "    \n",
    "    prediction_testset0 = []\n",
    "    for i in range(len(likelihood_0_testset0)):\n",
    "        if likelihood_0_testset0[i] > likelihood_1_testset0[i]: \n",
    "            prediction_testset0.append(0)\n",
    "        else: prediction_testset0.append(1)\n",
    "    \n",
    "    # P(x|y=0) = P(feature1 of x|y=0) * P(feature2 of x | y=0)  where x is a sample image from test1\n",
    "    likelihood_0_testset1 = calculate_pdf(test_mean1, mean_feature1_0, var_feature1_0) * calculate_pdf(test_sd1, mean_feature2_0, var_feature2_0)\n",
    "    \n",
    "    # P(x|y=1) = P(feature1 of x|y=1) * P(feature2 of x | y=0)  where x is a sample image from test1\n",
    "    likelihood_1_testset1 = calculate_pdf(test_mean1, mean_feature1_1, var_feature1_1) * calculate_pdf(test_sd1, mean_feature2_1, var_feature2_1)\n",
    "    \n",
    "    # make a prediction whether a value in test0 belongs to class 0 or 1 by returning the the greater likelihood\n",
    "    #prediction_testset1 = (likelihood_1_testset1 > likelihood_0_testset1).astype(int)\n",
    "    prediction_testset1 = []\n",
    "    for i in range(len(likelihood_0_testset1)):\n",
    "        if likelihood_0_testset1[i] > likelihood_1_testset1[i]: \n",
    "            prediction_testset1.append(0)\n",
    "        else: prediction_testset1.append(1)\n",
    "    \n",
    "    accuracy_testset0 = (len(prediction_testset0) - sum(prediction_testset0)) / len(test0)\n",
    "    accuracy_testset1 = sum(prediction_testset1) / len(test1)\n",
    "    #print(accuracy_testset1)\n",
    "    #print(tr -1)\n",
    "    # print(tr[:, (1,2)])\n",
    "    # plt.scatter(np.arange(len(test0)),test_mean0, s=0.5)\n",
    "    # plt.scatter(np.arange(5000),mean0, s=0.5)\n",
    "    # plt.show()\n",
    "    result = [\"1391\", mean_feature1_0, var_feature1_0, mean_feature2_0, var_feature2_0, mean_feature1_1, var_feature1_1, mean_feature2_1, var_feature2_1, accuracy_testset0, accuracy_testset1]\n",
    "    return result\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(images_arr):\n",
    "    length = len(images_arr) # length is 5000 for both train0 and train1\n",
    "    pixels_per_image = images_arr[0].size # 784 pixels per image\n",
    "    # reshape each trainset from 3D (5000, 28, 28) to 2D (5000, 784), thus flattening each individual pixels array\n",
    "    images_arr_reshaped = images_arr.reshape(length, pixels_per_image)\n",
    "    # mean and standard deviation are calculated along axis 1 (rows) of each trainset. Each row represents 1 image array\n",
    "    mean = np.mean(images_arr_reshaped, axis=1)\n",
    "    sd = np.std(images_arr_reshaped, axis=1)\n",
    "    return mean, sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_parameters(features):\n",
    "    mean = np.mean(features)\n",
    "    var = np.var(features)\n",
    "    return mean, var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_pdf(test_datapoints, mean, variance):\n",
    "    # result = 0\n",
    "    # for i in test_datapoint:\n",
    "    # probabilites of each test datapoint in test_datapoints array are calculated element-wise\n",
    "    pdf =  np.exp(-np.square(test_datapoints - mean))/(2 * variance)/np.sqrt(2 * np.pi * variance)\n",
    "     #   result = result + pdf\n",
    "    return pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Note:**\n",
    "\n",
    "* Your output should be a list in the following format:\n",
    "['ASUId',\n",
    "Mean_of_feature1_for_digit0, Variance_of_feature1_for_digit0,\n",
    "Mean_of_feature2_for_digit0, Variance_of_feature2_for_digit0 ,\n",
    "Mean_of_feature1_for_digit1, Variance_of_feature1_for_digit1,\n",
    "Mean_of_feature2_for_digit1, Variance_of_feature2_for_digit1,\n",
    "Accuracy_for_digit0testset, Accuracy_for_digit1testset]\n",
    "* The **order** of these 11 components are important.\n",
    "* Please print the result in the same cell that contains the comment `\"### TEST FUNCTION: test_question1\"` so that the autograder can capture your output and provide accurate feedback. Do not print anything else in the code cell below.\n",
    "* You can divide the code into different cells but the output should be printed in the cell containing the comment `\"### TEST FUNCTION: test_question1\"` \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1391', 44.16709005102041, 116.55307458838448, 87.38473381655496, 102.99175290160784, 19.400870153061224, 31.92200532942518, 61.39287609944414, 83.60005463130301, 0.8448979591836735, 0.9356828193832599]\n"
     ]
    }
   ],
   "source": [
    "### TEST FUNCTION: test_question1\n",
    "# DO NOT REMOVE THE ABOVE LINE\n",
    "print(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
